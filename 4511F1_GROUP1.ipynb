{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset from an Excel file into a pandas DataFrame\n",
        "file_path = '/content/SP_7JXQ_A_no-H2O_1cons_M1-div_arm_hb_16rota_new-smiles_dedup_full_columns_sample.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "print(f\"Original dataset size:\",df.shape)\n",
        "# Remove duplicate entries\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Dataset size after removing duplicates: {df.shape}\")\n",
        "threshold = 0.8  # Threshold of 80% missing values\n",
        "df_cleaned = df.dropna(axis='columns', thresh=int(threshold * len(df)))\n",
        "# Shape of the new dataset\n",
        "print(f\"Dataset size after handling missing values:\", df_cleaned.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QZdYlnYLrNr",
        "outputId": "2115dd65-5d5e-45fb-eda7-5f478c2b9217"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: (999, 438)\n",
            "Dataset size after removing duplicates: (999, 438)\n",
            "Dataset size after handling missing values: (999, 351)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit-pypi\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Descriptors, AllChem\n",
        "import pandas as pd\n",
        "\n",
        "# Function to compute molecular descriptors\n",
        "def compute_descriptors(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:  # SMILES parsing check\n",
        "        return [None] * 4  # Adjust the number if you change the number of descriptors\n",
        "    return [\n",
        "        Descriptors.MolWt(mol),\n",
        "        Descriptors.MolLogP(mol),\n",
        "        Descriptors.NumHDonors(mol),\n",
        "        Descriptors.NumHAcceptors(mol)\n",
        "    ]\n",
        "\n",
        "# Function to compute ECFP (Morgan) fingerprints\n",
        "def compute_fingerprints(smiles):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:  # SMILES parsing check\n",
        "        return [None] * 2048  # Adjust if you change the fingerprint length\n",
        "    return list(AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048))\n",
        "\n",
        "# Assuming 'df' is your DataFrame and 'SMILES' is the column with the molecular data\n",
        "\n",
        "# Ensure all SMILES data are strings and filter out any rows where SMILES might be NaN or improper format\n",
        "df['SMILES'] = df['SMILES'].astype(str)\n",
        "df = df[df['SMILES'] != 'nan']\n",
        "\n",
        "# Creating new DataFrame columns for descriptors\n",
        "descriptor_names = ['MolWt', 'LogP', 'NumHDonors', 'NumHAcceptors']\n",
        "descriptors = df['SMILES'].apply(lambda x: pd.Series(compute_descriptors(x), index=descriptor_names))\n",
        "\n",
        "# Creating new DataFrame columns for fingerprints\n",
        "fingerprint_names = [f'Bit_{i}' for i in range(2048)]  # Naming bits for clarity\n",
        "fingerprints = df['SMILES'].apply(lambda x: pd.Series(compute_fingerprints(x), index=fingerprint_names))\n",
        "\n",
        "# Concatenating all features (descriptors and fingerprints) with the original DataFrame\n",
        "full_features_df = pd.concat([df, descriptors, fingerprints], axis=1)\n",
        "# Print the first few rows of the descriptors dataframe\n",
        "print(\"First few rows of molecular descriptors:\")\n",
        "print(descriptors.head())\n",
        "\n",
        "# Print the first few rows of the fingerprints dataframe\n",
        "print(\"First few rows of molecular fingerprints:\")\n",
        "print(fingerprints.head())\n",
        "# Assuming 'df' contains your original data including 'Docking Score'\n",
        "# and 'descriptors' and 'fingerprints' are your feature DataFrames\n",
        "combined_df = pd.concat([df, descriptors, fingerprints], axis=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DEUqE04Ly1S",
        "outputId": "c3556190-c7f4-4f06-d677-ab162c326682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.10/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n",
            "First few rows of molecular descriptors:\n",
            "     MolWt     LogP  NumHDonors  NumHAcceptors\n",
            "1  422.532  5.46710         3.0            2.0\n",
            "2  494.667  5.14340         1.0            7.0\n",
            "3  434.499  5.91494         1.0            6.0\n",
            "4  488.931  3.60720         2.0            4.0\n",
            "5  464.500  4.93560         1.0            4.0\n",
            "First few rows of molecular fingerprints:\n",
            "   Bit_0  Bit_1  Bit_2  Bit_3  Bit_4  Bit_5  Bit_6  Bit_7  Bit_8  Bit_9  ...  \\\n",
            "1      0      1      0      0      0      0      0      0      0      0  ...   \n",
            "2      0      0      0      0      0      0      0      0      0      0  ...   \n",
            "3      0      0      0      0      0      0      0      0      0      0  ...   \n",
            "4      0      0      0      0      0      0      0      0      0      0  ...   \n",
            "5      0      0      0      0      0      0      0      0      0      0  ...   \n",
            "\n",
            "   Bit_2038  Bit_2039  Bit_2040  Bit_2041  Bit_2042  Bit_2043  Bit_2044  \\\n",
            "1         0         0         0         0         0         0         0   \n",
            "2         0         0         0         0         0         0         1   \n",
            "3         0         0         0         0         0         0         0   \n",
            "4         0         0         0         0         0         0         0   \n",
            "5         0         0         0         0         0         0         0   \n",
            "\n",
            "   Bit_2045  Bit_2046  Bit_2047  \n",
            "1         0         0         0  \n",
            "2         0         0         0  \n",
            "3         0         0         0  \n",
            "4         0         0         0  \n",
            "5         0         0         0  \n",
            "\n",
            "[5 rows x 2048 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print all column names in the DataFrame\n",
        "all_columns = list(combined_df.columns)\n",
        "print(all_columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnmM30AP6pij",
        "outputId": "2606c5dc-4d48-44fc-de96-7446d440db51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Stars', 'Title', 'Entry ID', 'Entry Name', 'Date Added', 'Date Modified', 'converted selenomethionines', 'created disulfur', 'prepared', 'Source File Index', 'PDB CRYST1 z', 'EEKEYHAEGG Homology Similarity', 'EEKEYHAEGG Homology Stem Beta', 'EEKEYHAEGG Homology Stem Dist', 'EEKEYHAEGG Homology Stem Gamma', 'EKEYHAEGGK Homology Similarity', 'EKEYHAEGGK Homology Stem Beta', 'EKEYHAEGGK Homology Stem Dist', 'EKEYHAEGGK Homology Stem Gamma', 'GAEEKEYHAEGG Homology Similarity', 'GAEEKEYHAEGG Homology Stem Beta', 'GAEEKEYHAEGG Homology Stem Dist', 'GAEEKEYHAEGG Homology Stem Gamma', 'Bend Energy-S-OPLS', 'Dihedral Energy-S-OPLS', 'El-14 Energy-S-OPLS', 'Electrostatic Energy-S-OPLS', 'LJ-14 Energy-S-OPLS', 'Max Derivative-S-OPLS', 'Potential Energy-S-OPLS', 'RMS Derivative-S-OPLS', 'Stretch Energy-S-OPLS', 'Van der Waals Energy-S-OPLS', 'target temperature', 'PDB CRYST1 a', 'PDB CRYST1 alpha', 'PDB CRYST1 b', 'PDB CRYST1 beta', 'PDB CRYST1 c', 'PDB CRYST1 gamma', 'PDB EXPDTA PH', 'PDB EXPDTA TEMPERATURE', 'PDB R', 'PDB RESOLUTION', 'PDB Rfree', 'preprocess pH', 'EEKEYHAEGG Homology Loopres', 'EEKEYHAEGG Homology Seq', 'EEKEYHAEGG Homology Source', 'EEKEYHAEGG Homology Stemres', 'EEKEYHAEGG Seq', 'EKEYHAEGGK Homology Loopres', 'EKEYHAEGGK Homology Seq', 'EKEYHAEGGK Homology Source', 'EKEYHAEGGK Homology Stemres', 'EKEYHAEGGK Seq', 'GAEEKEYHAEGG Homology Loopres', 'GAEEKEYHAEGG Homology Seq', 'GAEEKEYHAEGG Homology Source', 'GAEEKEYHAEGG Homology Stemres', 'GAEEKEYHAEGG Seq', 'OPLSVersion', 'Source File', 'Source Path', 'PDB CLASSIFICATION', 'PDB CRYST1 Space Group', 'PDB DEPOSITION DATE', 'PDB EXPDTA', 'PDB ID', 'PDB REMARK 350 Biomolecule 1 Transform 1 Chains', 'PDB REMARK 350 Biomolecule 1 Transform 1 Matrix 1', 'PDB REMARK 350 Biomolecule 1 Transform 2 Chains', 'PDB REMARK 350 Biomolecule 1 Transform 2 Matrix 2', 'PDB REMARK 350 Biomolecule 2 Transform 1 Chains', 'PDB REMARK 350 Biomolecule 2 Transform 1 Matrix 1', 'PDB REMARK 350 Biomolecule 2 Transform 2 Chains', 'PDB REMARK 350 Biomolecule 2 Transform 2 Matrix 2', 'PDB TITLE', 'PDB format version', 'het states', 'prepared with version', 'grid version', 'gridbox xcent', 'gridbox ycent', 'gridbox zcent', 'gridbox xrange', 'gridbox yrange', 'gridbox zrange', 'gridbox ligxrange', 'gridbox ligyrange', 'gridbox ligzrange', 'grid type', 'receptor', 'SMILES', 'title backup', 'mmshare version', 'label', 'flags', 'input', 'cmdline', 'Ionization Penalty', 'Ionization Penalty Charging', 'Ionization Penalty Neutral', 'State Penalty', 'Charging Adjusted Penalty', 'Tot Q', 'Tot abs Q', 'Force Field', 'Energy', 'Chiralities Consistent', 'Variant', 'variant', 'glide gridfile', 'glide lignum', 'glide rotatable bonds', 'docking score', 'glide ligand efficiency', 'glide ligand efficiency sa', 'glide ligand efficiency ln', 'glide gscore', 'glide lipo', 'glide hbond', 'glide metal', 'glide rewards', 'glide evdw', 'glide ecoul', 'glide erotb', 'glide esite', 'glide emodel', 'glide energy', 'glide einternal', 'glide emodel strain', 'glide gscore strain', 'glide confnum', 'glide posenum', 'glide eff state penalty', 'conssat A:GLU:758:OE2(hbond)', 'conssat A:ASP:855:OD1(hbond)', 'conssat A:PHE:856:O(hbond)', 'conssat A:THR:854:OG1(hbond)', 'conssat A:THR:854:HG1(hbond)', 'conssat A:GLU:762:OE2(hbond)', 'conssat A:LEU:777:H(hbond)', 'conssat A:LYS:745:H(hbond)', 'conssat A:LYS:745:HZ1(hbond)', 'conssat A:CYS:775:O(hbond)', 'res:A1103 vdw', 'res:A1103 coul', 'res:A1103 hbond', 'res:A1103 dist', 'res:A1103 Eint', 'res:A1101 vdw', 'res:A1101 coul', 'res:A1101 hbond', 'res:A1101 dist', 'res:A1101 Eint', 'res:A863 vdw', 'res:A863 coul', 'res:A863 hbond', 'res:A863 dist', 'res:A863 Eint', 'res:A862 vdw', 'res:A862 coul', 'res:A862 hbond', 'res:A862 dist', 'res:A862 Eint', 'res:A861 vdw', 'res:A861 coul', 'res:A861 hbond', 'res:A861 dist', 'res:A861 Eint', 'res:A860 vdw', 'res:A860 coul', 'res:A860 hbond', 'res:A860 dist', 'res:A860 Eint', 'res:A859 vdw', 'res:A859 coul', 'res:A859 hbond', 'res:A859 dist', 'res:A859 Eint', 'res:A858 vdw', 'res:A858 coul', 'res:A858 hbond', 'res:A858 dist', 'res:A858 Eint', 'res:A857 vdw', 'res:A857 coul', 'res:A857 hbond', 'res:A857 dist', 'res:A857 Eint', 'res:A856 vdw', 'res:A856 coul', 'res:A856 hbond', 'res:A856 dist', 'res:A856 Eint', 'res:A855 vdw', 'res:A855 coul', 'res:A855 hbond', 'res:A855 dist', 'res:A855 Eint', 'res:A854 vdw', 'res:A854 coul', 'res:A854 hbond', 'res:A854 dist', 'res:A854 Eint', 'res:A837 vdw', 'res:A837 coul', 'res:A837 hbond', 'res:A837 dist', 'res:A837 Eint', 'res:A836 vdw', 'res:A836 coul', 'res:A836 hbond', 'res:A836 dist', 'res:A836 Eint', 'res:A835 vdw', 'res:A835 coul', 'res:A835 hbond', 'res:A835 dist', 'res:A835 Eint', 'res:A834 vdw', 'res:A834 coul', 'res:A834 hbond', 'res:A834 dist', 'res:A834 Eint', 'res:A833 vdw', 'res:A833 coul', 'res:A833 hbond', 'res:A833 dist', 'res:A833 Eint', 'res:A790 vdw', 'res:A790 coul', 'res:A790 hbond', 'res:A790 dist', 'res:A790 Eint', 'res:A789 vdw', 'res:A789 coul', 'res:A789 hbond', 'res:A789 dist', 'res:A789 Eint', 'res:A788 vdw', 'res:A788 coul', 'res:A788 hbond', 'res:A788 dist', 'res:A788 Eint', 'res:A787 vdw', 'res:A787 coul', 'res:A787 hbond', 'res:A787 dist', 'res:A787 Eint', 'res:A786 vdw', 'res:A786 coul', 'res:A786 hbond', 'res:A786 dist', 'res:A786 Eint', 'res:A785 vdw', 'res:A785 coul', 'res:A785 hbond', 'res:A785 dist', 'res:A785 Eint', 'res:A783 vdw', 'res:A783 coul', 'res:A783 hbond', 'res:A783 dist', 'res:A783 Eint', 'res:A782 vdw', 'res:A782 coul', 'res:A782 hbond', 'res:A782 dist', 'res:A782 Eint', 'res:A781 vdw', 'res:A781 coul', 'res:A781 hbond', 'res:A781 dist', 'res:A781 Eint', 'res:A780 vdw', 'res:A780 coul', 'res:A780 hbond', 'res:A780 dist', 'res:A780 Eint', 'res:A779 vdw', 'res:A779 coul', 'res:A779 hbond', 'res:A779 dist', 'res:A779 Eint', 'res:A778 vdw', 'res:A778 coul', 'res:A778 hbond', 'res:A778 dist', 'res:A778 Eint', 'res:A777 vdw', 'res:A777 coul', 'res:A777 hbond', 'res:A777 dist', 'res:A777 Eint', 'res:A767 vdw', 'res:A767 coul', 'res:A767 hbond', 'res:A767 dist', 'res:A767 Eint', 'res:A766 vdw', 'res:A766 coul', 'res:A766 hbond', 'res:A766 dist', 'res:A766 Eint', 'res:A765 vdw', 'res:A765 coul', 'res:A765 hbond', 'res:A765 dist', 'res:A765 Eint', 'res:A764 vdw', 'res:A764 coul', 'res:A764 hbond', 'res:A764 dist', 'res:A764 Eint', 'res:A763 vdw', 'res:A763 coul', 'res:A763 hbond', 'res:A763 dist', 'res:A763 Eint', 'res:A762 vdw', 'res:A762 coul', 'res:A762 hbond', 'res:A762 dist', 'res:A762 Eint', 'res:A761 vdw', 'res:A761 coul', 'res:A761 hbond', 'res:A761 dist', 'res:A761 Eint', 'res:A760 vdw', 'res:A760 coul', 'res:A760 hbond', 'res:A760 dist', 'res:A760 Eint', 'res:A759 vdw', 'res:A759 coul', 'res:A759 hbond', 'res:A759 dist', 'res:A759 Eint', 'res:A758 vdw', 'res:A758 coul', 'res:A758 hbond', 'res:A758 dist', 'res:A758 Eint', 'res:A757 vdw', 'res:A757 coul', 'res:A757 hbond', 'res:A757 dist', 'res:A757 Eint', 'res:A756 vdw', 'res:A756 coul', 'res:A756 hbond', 'res:A756 dist', 'res:A756 Eint', 'res:A755 vdw', 'res:A755 coul', 'res:A755 hbond', 'res:A755 dist', 'res:A755 Eint', 'res:A751 vdw', 'res:A751 coul', 'res:A751 hbond', 'res:A751 dist', 'res:A751 Eint', 'res:A750 vdw', 'res:A750 coul', 'res:A750 hbond', 'res:A750 dist', 'res:A750 Eint', 'res:A749 vdw', 'res:A749 coul', 'res:A749 hbond', 'res:A749 dist', 'res:A749 Eint', 'res:A748 vdw', 'res:A748 coul', 'res:A748 hbond', 'res:A748 dist', 'res:A748 Eint', 'res:A747 vdw', 'res:A747 coul', 'res:A747 hbond', 'res:A747 dist', 'res:A747 Eint', 'res:A746 vdw', 'res:A746 coul', 'res:A746 hbond', 'res:A746 dist', 'res:A746 Eint', 'res:A745 vdw', 'res:A745 coul', 'res:A745 hbond', 'res:A745 dist', 'res:A745 Eint', 'res:A744 vdw', 'res:A744 coul', 'res:A744 hbond', 'res:A744 dist', 'res:A744 Eint', 'res:A726 vdw', 'res:A726 coul', 'res:A726 hbond', 'res:A726 dist', 'res:A726 Eint', 'res:A725 vdw', 'res:A725 coul', 'res:A725 hbond', 'res:A725 dist', 'res:A725 Eint', 'res:A724 vdw', 'res:A724 coul', 'res:A724 hbond', 'res:A724 dist', 'res:A724 Eint', 'res:A723 vdw', 'res:A723 coul', 'res:A723 hbond', 'res:A723 dist', 'res:A723 Eint', 'res:A722 vdw', 'res:A722 coul', 'res:A722 hbond', 'res:A722 dist', 'res:A722 Eint', 'res:A721 vdw', 'res:A721 coul', 'res:A721 hbond', 'res:A721 dist', 'res:A721 Eint', 'res:A704 vdw', 'res:A704 coul', 'res:A704 hbond', 'res:A704 dist', 'res:A704 Eint', 'tautomer probability', 'Chemistry Notes', 'MolWt', 'LogP', 'NumHDonors', 'NumHAcceptors', 'Bit_0', 'Bit_1', 'Bit_2', 'Bit_3', 'Bit_4', 'Bit_5', 'Bit_6', 'Bit_7', 'Bit_8', 'Bit_9', 'Bit_10', 'Bit_11', 'Bit_12', 'Bit_13', 'Bit_14', 'Bit_15', 'Bit_16', 'Bit_17', 'Bit_18', 'Bit_19', 'Bit_20', 'Bit_21', 'Bit_22', 'Bit_23', 'Bit_24', 'Bit_25', 'Bit_26', 'Bit_27', 'Bit_28', 'Bit_29', 'Bit_30', 'Bit_31', 'Bit_32', 'Bit_33', 'Bit_34', 'Bit_35', 'Bit_36', 'Bit_37', 'Bit_38', 'Bit_39', 'Bit_40', 'Bit_41', 'Bit_42', 'Bit_43', 'Bit_44', 'Bit_45', 'Bit_46', 'Bit_47', 'Bit_48', 'Bit_49', 'Bit_50', 'Bit_51', 'Bit_52', 'Bit_53', 'Bit_54', 'Bit_55', 'Bit_56', 'Bit_57', 'Bit_58', 'Bit_59', 'Bit_60', 'Bit_61', 'Bit_62', 'Bit_63', 'Bit_64', 'Bit_65', 'Bit_66', 'Bit_67', 'Bit_68', 'Bit_69', 'Bit_70', 'Bit_71', 'Bit_72', 'Bit_73', 'Bit_74', 'Bit_75', 'Bit_76', 'Bit_77', 'Bit_78', 'Bit_79', 'Bit_80', 'Bit_81', 'Bit_82', 'Bit_83', 'Bit_84', 'Bit_85', 'Bit_86', 'Bit_87', 'Bit_88', 'Bit_89', 'Bit_90', 'Bit_91', 'Bit_92', 'Bit_93', 'Bit_94', 'Bit_95', 'Bit_96', 'Bit_97', 'Bit_98', 'Bit_99', 'Bit_100', 'Bit_101', 'Bit_102', 'Bit_103', 'Bit_104', 'Bit_105', 'Bit_106', 'Bit_107', 'Bit_108', 'Bit_109', 'Bit_110', 'Bit_111', 'Bit_112', 'Bit_113', 'Bit_114', 'Bit_115', 'Bit_116', 'Bit_117', 'Bit_118', 'Bit_119', 'Bit_120', 'Bit_121', 'Bit_122', 'Bit_123', 'Bit_124', 'Bit_125', 'Bit_126', 'Bit_127', 'Bit_128', 'Bit_129', 'Bit_130', 'Bit_131', 'Bit_132', 'Bit_133', 'Bit_134', 'Bit_135', 'Bit_136', 'Bit_137', 'Bit_138', 'Bit_139', 'Bit_140', 'Bit_141', 'Bit_142', 'Bit_143', 'Bit_144', 'Bit_145', 'Bit_146', 'Bit_147', 'Bit_148', 'Bit_149', 'Bit_150', 'Bit_151', 'Bit_152', 'Bit_153', 'Bit_154', 'Bit_155', 'Bit_156', 'Bit_157', 'Bit_158', 'Bit_159', 'Bit_160', 'Bit_161', 'Bit_162', 'Bit_163', 'Bit_164', 'Bit_165', 'Bit_166', 'Bit_167', 'Bit_168', 'Bit_169', 'Bit_170', 'Bit_171', 'Bit_172', 'Bit_173', 'Bit_174', 'Bit_175', 'Bit_176', 'Bit_177', 'Bit_178', 'Bit_179', 'Bit_180', 'Bit_181', 'Bit_182', 'Bit_183', 'Bit_184', 'Bit_185', 'Bit_186', 'Bit_187', 'Bit_188', 'Bit_189', 'Bit_190', 'Bit_191', 'Bit_192', 'Bit_193', 'Bit_194', 'Bit_195', 'Bit_196', 'Bit_197', 'Bit_198', 'Bit_199', 'Bit_200', 'Bit_201', 'Bit_202', 'Bit_203', 'Bit_204', 'Bit_205', 'Bit_206', 'Bit_207', 'Bit_208', 'Bit_209', 'Bit_210', 'Bit_211', 'Bit_212', 'Bit_213', 'Bit_214', 'Bit_215', 'Bit_216', 'Bit_217', 'Bit_218', 'Bit_219', 'Bit_220', 'Bit_221', 'Bit_222', 'Bit_223', 'Bit_224', 'Bit_225', 'Bit_226', 'Bit_227', 'Bit_228', 'Bit_229', 'Bit_230', 'Bit_231', 'Bit_232', 'Bit_233', 'Bit_234', 'Bit_235', 'Bit_236', 'Bit_237', 'Bit_238', 'Bit_239', 'Bit_240', 'Bit_241', 'Bit_242', 'Bit_243', 'Bit_244', 'Bit_245', 'Bit_246', 'Bit_247', 'Bit_248', 'Bit_249', 'Bit_250', 'Bit_251', 'Bit_252', 'Bit_253', 'Bit_254', 'Bit_255', 'Bit_256', 'Bit_257', 'Bit_258', 'Bit_259', 'Bit_260', 'Bit_261', 'Bit_262', 'Bit_263', 'Bit_264', 'Bit_265', 'Bit_266', 'Bit_267', 'Bit_268', 'Bit_269', 'Bit_270', 'Bit_271', 'Bit_272', 'Bit_273', 'Bit_274', 'Bit_275', 'Bit_276', 'Bit_277', 'Bit_278', 'Bit_279', 'Bit_280', 'Bit_281', 'Bit_282', 'Bit_283', 'Bit_284', 'Bit_285', 'Bit_286', 'Bit_287', 'Bit_288', 'Bit_289', 'Bit_290', 'Bit_291', 'Bit_292', 'Bit_293', 'Bit_294', 'Bit_295', 'Bit_296', 'Bit_297', 'Bit_298', 'Bit_299', 'Bit_300', 'Bit_301', 'Bit_302', 'Bit_303', 'Bit_304', 'Bit_305', 'Bit_306', 'Bit_307', 'Bit_308', 'Bit_309', 'Bit_310', 'Bit_311', 'Bit_312', 'Bit_313', 'Bit_314', 'Bit_315', 'Bit_316', 'Bit_317', 'Bit_318', 'Bit_319', 'Bit_320', 'Bit_321', 'Bit_322', 'Bit_323', 'Bit_324', 'Bit_325', 'Bit_326', 'Bit_327', 'Bit_328', 'Bit_329', 'Bit_330', 'Bit_331', 'Bit_332', 'Bit_333', 'Bit_334', 'Bit_335', 'Bit_336', 'Bit_337', 'Bit_338', 'Bit_339', 'Bit_340', 'Bit_341', 'Bit_342', 'Bit_343', 'Bit_344', 'Bit_345', 'Bit_346', 'Bit_347', 'Bit_348', 'Bit_349', 'Bit_350', 'Bit_351', 'Bit_352', 'Bit_353', 'Bit_354', 'Bit_355', 'Bit_356', 'Bit_357', 'Bit_358', 'Bit_359', 'Bit_360', 'Bit_361', 'Bit_362', 'Bit_363', 'Bit_364', 'Bit_365', 'Bit_366', 'Bit_367', 'Bit_368', 'Bit_369', 'Bit_370', 'Bit_371', 'Bit_372', 'Bit_373', 'Bit_374', 'Bit_375', 'Bit_376', 'Bit_377', 'Bit_378', 'Bit_379', 'Bit_380', 'Bit_381', 'Bit_382', 'Bit_383', 'Bit_384', 'Bit_385', 'Bit_386', 'Bit_387', 'Bit_388', 'Bit_389', 'Bit_390', 'Bit_391', 'Bit_392', 'Bit_393', 'Bit_394', 'Bit_395', 'Bit_396', 'Bit_397', 'Bit_398', 'Bit_399', 'Bit_400', 'Bit_401', 'Bit_402', 'Bit_403', 'Bit_404', 'Bit_405', 'Bit_406', 'Bit_407', 'Bit_408', 'Bit_409', 'Bit_410', 'Bit_411', 'Bit_412', 'Bit_413', 'Bit_414', 'Bit_415', 'Bit_416', 'Bit_417', 'Bit_418', 'Bit_419', 'Bit_420', 'Bit_421', 'Bit_422', 'Bit_423', 'Bit_424', 'Bit_425', 'Bit_426', 'Bit_427', 'Bit_428', 'Bit_429', 'Bit_430', 'Bit_431', 'Bit_432', 'Bit_433', 'Bit_434', 'Bit_435', 'Bit_436', 'Bit_437', 'Bit_438', 'Bit_439', 'Bit_440', 'Bit_441', 'Bit_442', 'Bit_443', 'Bit_444', 'Bit_445', 'Bit_446', 'Bit_447', 'Bit_448', 'Bit_449', 'Bit_450', 'Bit_451', 'Bit_452', 'Bit_453', 'Bit_454', 'Bit_455', 'Bit_456', 'Bit_457', 'Bit_458', 'Bit_459', 'Bit_460', 'Bit_461', 'Bit_462', 'Bit_463', 'Bit_464', 'Bit_465', 'Bit_466', 'Bit_467', 'Bit_468', 'Bit_469', 'Bit_470', 'Bit_471', 'Bit_472', 'Bit_473', 'Bit_474', 'Bit_475', 'Bit_476', 'Bit_477', 'Bit_478', 'Bit_479', 'Bit_480', 'Bit_481', 'Bit_482', 'Bit_483', 'Bit_484', 'Bit_485', 'Bit_486', 'Bit_487', 'Bit_488', 'Bit_489', 'Bit_490', 'Bit_491', 'Bit_492', 'Bit_493', 'Bit_494', 'Bit_495', 'Bit_496', 'Bit_497', 'Bit_498', 'Bit_499', 'Bit_500', 'Bit_501', 'Bit_502', 'Bit_503', 'Bit_504', 'Bit_505', 'Bit_506', 'Bit_507', 'Bit_508', 'Bit_509', 'Bit_510', 'Bit_511', 'Bit_512', 'Bit_513', 'Bit_514', 'Bit_515', 'Bit_516', 'Bit_517', 'Bit_518', 'Bit_519', 'Bit_520', 'Bit_521', 'Bit_522', 'Bit_523', 'Bit_524', 'Bit_525', 'Bit_526', 'Bit_527', 'Bit_528', 'Bit_529', 'Bit_530', 'Bit_531', 'Bit_532', 'Bit_533', 'Bit_534', 'Bit_535', 'Bit_536', 'Bit_537', 'Bit_538', 'Bit_539', 'Bit_540', 'Bit_541', 'Bit_542', 'Bit_543', 'Bit_544', 'Bit_545', 'Bit_546', 'Bit_547', 'Bit_548', 'Bit_549', 'Bit_550', 'Bit_551', 'Bit_552', 'Bit_553', 'Bit_554', 'Bit_555', 'Bit_556', 'Bit_557', 'Bit_558', 'Bit_559', 'Bit_560', 'Bit_561', 'Bit_562', 'Bit_563', 'Bit_564', 'Bit_565', 'Bit_566', 'Bit_567', 'Bit_568', 'Bit_569', 'Bit_570', 'Bit_571', 'Bit_572', 'Bit_573', 'Bit_574', 'Bit_575', 'Bit_576', 'Bit_577', 'Bit_578', 'Bit_579', 'Bit_580', 'Bit_581', 'Bit_582', 'Bit_583', 'Bit_584', 'Bit_585', 'Bit_586', 'Bit_587', 'Bit_588', 'Bit_589', 'Bit_590', 'Bit_591', 'Bit_592', 'Bit_593', 'Bit_594', 'Bit_595', 'Bit_596', 'Bit_597', 'Bit_598', 'Bit_599', 'Bit_600', 'Bit_601', 'Bit_602', 'Bit_603', 'Bit_604', 'Bit_605', 'Bit_606', 'Bit_607', 'Bit_608', 'Bit_609', 'Bit_610', 'Bit_611', 'Bit_612', 'Bit_613', 'Bit_614', 'Bit_615', 'Bit_616', 'Bit_617', 'Bit_618', 'Bit_619', 'Bit_620', 'Bit_621', 'Bit_622', 'Bit_623', 'Bit_624', 'Bit_625', 'Bit_626', 'Bit_627', 'Bit_628', 'Bit_629', 'Bit_630', 'Bit_631', 'Bit_632', 'Bit_633', 'Bit_634', 'Bit_635', 'Bit_636', 'Bit_637', 'Bit_638', 'Bit_639', 'Bit_640', 'Bit_641', 'Bit_642', 'Bit_643', 'Bit_644', 'Bit_645', 'Bit_646', 'Bit_647', 'Bit_648', 'Bit_649', 'Bit_650', 'Bit_651', 'Bit_652', 'Bit_653', 'Bit_654', 'Bit_655', 'Bit_656', 'Bit_657', 'Bit_658', 'Bit_659', 'Bit_660', 'Bit_661', 'Bit_662', 'Bit_663', 'Bit_664', 'Bit_665', 'Bit_666', 'Bit_667', 'Bit_668', 'Bit_669', 'Bit_670', 'Bit_671', 'Bit_672', 'Bit_673', 'Bit_674', 'Bit_675', 'Bit_676', 'Bit_677', 'Bit_678', 'Bit_679', 'Bit_680', 'Bit_681', 'Bit_682', 'Bit_683', 'Bit_684', 'Bit_685', 'Bit_686', 'Bit_687', 'Bit_688', 'Bit_689', 'Bit_690', 'Bit_691', 'Bit_692', 'Bit_693', 'Bit_694', 'Bit_695', 'Bit_696', 'Bit_697', 'Bit_698', 'Bit_699', 'Bit_700', 'Bit_701', 'Bit_702', 'Bit_703', 'Bit_704', 'Bit_705', 'Bit_706', 'Bit_707', 'Bit_708', 'Bit_709', 'Bit_710', 'Bit_711', 'Bit_712', 'Bit_713', 'Bit_714', 'Bit_715', 'Bit_716', 'Bit_717', 'Bit_718', 'Bit_719', 'Bit_720', 'Bit_721', 'Bit_722', 'Bit_723', 'Bit_724', 'Bit_725', 'Bit_726', 'Bit_727', 'Bit_728', 'Bit_729', 'Bit_730', 'Bit_731', 'Bit_732', 'Bit_733', 'Bit_734', 'Bit_735', 'Bit_736', 'Bit_737', 'Bit_738', 'Bit_739', 'Bit_740', 'Bit_741', 'Bit_742', 'Bit_743', 'Bit_744', 'Bit_745', 'Bit_746', 'Bit_747', 'Bit_748', 'Bit_749', 'Bit_750', 'Bit_751', 'Bit_752', 'Bit_753', 'Bit_754', 'Bit_755', 'Bit_756', 'Bit_757', 'Bit_758', 'Bit_759', 'Bit_760', 'Bit_761', 'Bit_762', 'Bit_763', 'Bit_764', 'Bit_765', 'Bit_766', 'Bit_767', 'Bit_768', 'Bit_769', 'Bit_770', 'Bit_771', 'Bit_772', 'Bit_773', 'Bit_774', 'Bit_775', 'Bit_776', 'Bit_777', 'Bit_778', 'Bit_779', 'Bit_780', 'Bit_781', 'Bit_782', 'Bit_783', 'Bit_784', 'Bit_785', 'Bit_786', 'Bit_787', 'Bit_788', 'Bit_789', 'Bit_790', 'Bit_791', 'Bit_792', 'Bit_793', 'Bit_794', 'Bit_795', 'Bit_796', 'Bit_797', 'Bit_798', 'Bit_799', 'Bit_800', 'Bit_801', 'Bit_802', 'Bit_803', 'Bit_804', 'Bit_805', 'Bit_806', 'Bit_807', 'Bit_808', 'Bit_809', 'Bit_810', 'Bit_811', 'Bit_812', 'Bit_813', 'Bit_814', 'Bit_815', 'Bit_816', 'Bit_817', 'Bit_818', 'Bit_819', 'Bit_820', 'Bit_821', 'Bit_822', 'Bit_823', 'Bit_824', 'Bit_825', 'Bit_826', 'Bit_827', 'Bit_828', 'Bit_829', 'Bit_830', 'Bit_831', 'Bit_832', 'Bit_833', 'Bit_834', 'Bit_835', 'Bit_836', 'Bit_837', 'Bit_838', 'Bit_839', 'Bit_840', 'Bit_841', 'Bit_842', 'Bit_843', 'Bit_844', 'Bit_845', 'Bit_846', 'Bit_847', 'Bit_848', 'Bit_849', 'Bit_850', 'Bit_851', 'Bit_852', 'Bit_853', 'Bit_854', 'Bit_855', 'Bit_856', 'Bit_857', 'Bit_858', 'Bit_859', 'Bit_860', 'Bit_861', 'Bit_862', 'Bit_863', 'Bit_864', 'Bit_865', 'Bit_866', 'Bit_867', 'Bit_868', 'Bit_869', 'Bit_870', 'Bit_871', 'Bit_872', 'Bit_873', 'Bit_874', 'Bit_875', 'Bit_876', 'Bit_877', 'Bit_878', 'Bit_879', 'Bit_880', 'Bit_881', 'Bit_882', 'Bit_883', 'Bit_884', 'Bit_885', 'Bit_886', 'Bit_887', 'Bit_888', 'Bit_889', 'Bit_890', 'Bit_891', 'Bit_892', 'Bit_893', 'Bit_894', 'Bit_895', 'Bit_896', 'Bit_897', 'Bit_898', 'Bit_899', 'Bit_900', 'Bit_901', 'Bit_902', 'Bit_903', 'Bit_904', 'Bit_905', 'Bit_906', 'Bit_907', 'Bit_908', 'Bit_909', 'Bit_910', 'Bit_911', 'Bit_912', 'Bit_913', 'Bit_914', 'Bit_915', 'Bit_916', 'Bit_917', 'Bit_918', 'Bit_919', 'Bit_920', 'Bit_921', 'Bit_922', 'Bit_923', 'Bit_924', 'Bit_925', 'Bit_926', 'Bit_927', 'Bit_928', 'Bit_929', 'Bit_930', 'Bit_931', 'Bit_932', 'Bit_933', 'Bit_934', 'Bit_935', 'Bit_936', 'Bit_937', 'Bit_938', 'Bit_939', 'Bit_940', 'Bit_941', 'Bit_942', 'Bit_943', 'Bit_944', 'Bit_945', 'Bit_946', 'Bit_947', 'Bit_948', 'Bit_949', 'Bit_950', 'Bit_951', 'Bit_952', 'Bit_953', 'Bit_954', 'Bit_955', 'Bit_956', 'Bit_957', 'Bit_958', 'Bit_959', 'Bit_960', 'Bit_961', 'Bit_962', 'Bit_963', 'Bit_964', 'Bit_965', 'Bit_966', 'Bit_967', 'Bit_968', 'Bit_969', 'Bit_970', 'Bit_971', 'Bit_972', 'Bit_973', 'Bit_974', 'Bit_975', 'Bit_976', 'Bit_977', 'Bit_978', 'Bit_979', 'Bit_980', 'Bit_981', 'Bit_982', 'Bit_983', 'Bit_984', 'Bit_985', 'Bit_986', 'Bit_987', 'Bit_988', 'Bit_989', 'Bit_990', 'Bit_991', 'Bit_992', 'Bit_993', 'Bit_994', 'Bit_995', 'Bit_996', 'Bit_997', 'Bit_998', 'Bit_999', 'Bit_1000', 'Bit_1001', 'Bit_1002', 'Bit_1003', 'Bit_1004', 'Bit_1005', 'Bit_1006', 'Bit_1007', 'Bit_1008', 'Bit_1009', 'Bit_1010', 'Bit_1011', 'Bit_1012', 'Bit_1013', 'Bit_1014', 'Bit_1015', 'Bit_1016', 'Bit_1017', 'Bit_1018', 'Bit_1019', 'Bit_1020', 'Bit_1021', 'Bit_1022', 'Bit_1023', 'Bit_1024', 'Bit_1025', 'Bit_1026', 'Bit_1027', 'Bit_1028', 'Bit_1029', 'Bit_1030', 'Bit_1031', 'Bit_1032', 'Bit_1033', 'Bit_1034', 'Bit_1035', 'Bit_1036', 'Bit_1037', 'Bit_1038', 'Bit_1039', 'Bit_1040', 'Bit_1041', 'Bit_1042', 'Bit_1043', 'Bit_1044', 'Bit_1045', 'Bit_1046', 'Bit_1047', 'Bit_1048', 'Bit_1049', 'Bit_1050', 'Bit_1051', 'Bit_1052', 'Bit_1053', 'Bit_1054', 'Bit_1055', 'Bit_1056', 'Bit_1057', 'Bit_1058', 'Bit_1059', 'Bit_1060', 'Bit_1061', 'Bit_1062', 'Bit_1063', 'Bit_1064', 'Bit_1065', 'Bit_1066', 'Bit_1067', 'Bit_1068', 'Bit_1069', 'Bit_1070', 'Bit_1071', 'Bit_1072', 'Bit_1073', 'Bit_1074', 'Bit_1075', 'Bit_1076', 'Bit_1077', 'Bit_1078', 'Bit_1079', 'Bit_1080', 'Bit_1081', 'Bit_1082', 'Bit_1083', 'Bit_1084', 'Bit_1085', 'Bit_1086', 'Bit_1087', 'Bit_1088', 'Bit_1089', 'Bit_1090', 'Bit_1091', 'Bit_1092', 'Bit_1093', 'Bit_1094', 'Bit_1095', 'Bit_1096', 'Bit_1097', 'Bit_1098', 'Bit_1099', 'Bit_1100', 'Bit_1101', 'Bit_1102', 'Bit_1103', 'Bit_1104', 'Bit_1105', 'Bit_1106', 'Bit_1107', 'Bit_1108', 'Bit_1109', 'Bit_1110', 'Bit_1111', 'Bit_1112', 'Bit_1113', 'Bit_1114', 'Bit_1115', 'Bit_1116', 'Bit_1117', 'Bit_1118', 'Bit_1119', 'Bit_1120', 'Bit_1121', 'Bit_1122', 'Bit_1123', 'Bit_1124', 'Bit_1125', 'Bit_1126', 'Bit_1127', 'Bit_1128', 'Bit_1129', 'Bit_1130', 'Bit_1131', 'Bit_1132', 'Bit_1133', 'Bit_1134', 'Bit_1135', 'Bit_1136', 'Bit_1137', 'Bit_1138', 'Bit_1139', 'Bit_1140', 'Bit_1141', 'Bit_1142', 'Bit_1143', 'Bit_1144', 'Bit_1145', 'Bit_1146', 'Bit_1147', 'Bit_1148', 'Bit_1149', 'Bit_1150', 'Bit_1151', 'Bit_1152', 'Bit_1153', 'Bit_1154', 'Bit_1155', 'Bit_1156', 'Bit_1157', 'Bit_1158', 'Bit_1159', 'Bit_1160', 'Bit_1161', 'Bit_1162', 'Bit_1163', 'Bit_1164', 'Bit_1165', 'Bit_1166', 'Bit_1167', 'Bit_1168', 'Bit_1169', 'Bit_1170', 'Bit_1171', 'Bit_1172', 'Bit_1173', 'Bit_1174', 'Bit_1175', 'Bit_1176', 'Bit_1177', 'Bit_1178', 'Bit_1179', 'Bit_1180', 'Bit_1181', 'Bit_1182', 'Bit_1183', 'Bit_1184', 'Bit_1185', 'Bit_1186', 'Bit_1187', 'Bit_1188', 'Bit_1189', 'Bit_1190', 'Bit_1191', 'Bit_1192', 'Bit_1193', 'Bit_1194', 'Bit_1195', 'Bit_1196', 'Bit_1197', 'Bit_1198', 'Bit_1199', 'Bit_1200', 'Bit_1201', 'Bit_1202', 'Bit_1203', 'Bit_1204', 'Bit_1205', 'Bit_1206', 'Bit_1207', 'Bit_1208', 'Bit_1209', 'Bit_1210', 'Bit_1211', 'Bit_1212', 'Bit_1213', 'Bit_1214', 'Bit_1215', 'Bit_1216', 'Bit_1217', 'Bit_1218', 'Bit_1219', 'Bit_1220', 'Bit_1221', 'Bit_1222', 'Bit_1223', 'Bit_1224', 'Bit_1225', 'Bit_1226', 'Bit_1227', 'Bit_1228', 'Bit_1229', 'Bit_1230', 'Bit_1231', 'Bit_1232', 'Bit_1233', 'Bit_1234', 'Bit_1235', 'Bit_1236', 'Bit_1237', 'Bit_1238', 'Bit_1239', 'Bit_1240', 'Bit_1241', 'Bit_1242', 'Bit_1243', 'Bit_1244', 'Bit_1245', 'Bit_1246', 'Bit_1247', 'Bit_1248', 'Bit_1249', 'Bit_1250', 'Bit_1251', 'Bit_1252', 'Bit_1253', 'Bit_1254', 'Bit_1255', 'Bit_1256', 'Bit_1257', 'Bit_1258', 'Bit_1259', 'Bit_1260', 'Bit_1261', 'Bit_1262', 'Bit_1263', 'Bit_1264', 'Bit_1265', 'Bit_1266', 'Bit_1267', 'Bit_1268', 'Bit_1269', 'Bit_1270', 'Bit_1271', 'Bit_1272', 'Bit_1273', 'Bit_1274', 'Bit_1275', 'Bit_1276', 'Bit_1277', 'Bit_1278', 'Bit_1279', 'Bit_1280', 'Bit_1281', 'Bit_1282', 'Bit_1283', 'Bit_1284', 'Bit_1285', 'Bit_1286', 'Bit_1287', 'Bit_1288', 'Bit_1289', 'Bit_1290', 'Bit_1291', 'Bit_1292', 'Bit_1293', 'Bit_1294', 'Bit_1295', 'Bit_1296', 'Bit_1297', 'Bit_1298', 'Bit_1299', 'Bit_1300', 'Bit_1301', 'Bit_1302', 'Bit_1303', 'Bit_1304', 'Bit_1305', 'Bit_1306', 'Bit_1307', 'Bit_1308', 'Bit_1309', 'Bit_1310', 'Bit_1311', 'Bit_1312', 'Bit_1313', 'Bit_1314', 'Bit_1315', 'Bit_1316', 'Bit_1317', 'Bit_1318', 'Bit_1319', 'Bit_1320', 'Bit_1321', 'Bit_1322', 'Bit_1323', 'Bit_1324', 'Bit_1325', 'Bit_1326', 'Bit_1327', 'Bit_1328', 'Bit_1329', 'Bit_1330', 'Bit_1331', 'Bit_1332', 'Bit_1333', 'Bit_1334', 'Bit_1335', 'Bit_1336', 'Bit_1337', 'Bit_1338', 'Bit_1339', 'Bit_1340', 'Bit_1341', 'Bit_1342', 'Bit_1343', 'Bit_1344', 'Bit_1345', 'Bit_1346', 'Bit_1347', 'Bit_1348', 'Bit_1349', 'Bit_1350', 'Bit_1351', 'Bit_1352', 'Bit_1353', 'Bit_1354', 'Bit_1355', 'Bit_1356', 'Bit_1357', 'Bit_1358', 'Bit_1359', 'Bit_1360', 'Bit_1361', 'Bit_1362', 'Bit_1363', 'Bit_1364', 'Bit_1365', 'Bit_1366', 'Bit_1367', 'Bit_1368', 'Bit_1369', 'Bit_1370', 'Bit_1371', 'Bit_1372', 'Bit_1373', 'Bit_1374', 'Bit_1375', 'Bit_1376', 'Bit_1377', 'Bit_1378', 'Bit_1379', 'Bit_1380', 'Bit_1381', 'Bit_1382', 'Bit_1383', 'Bit_1384', 'Bit_1385', 'Bit_1386', 'Bit_1387', 'Bit_1388', 'Bit_1389', 'Bit_1390', 'Bit_1391', 'Bit_1392', 'Bit_1393', 'Bit_1394', 'Bit_1395', 'Bit_1396', 'Bit_1397', 'Bit_1398', 'Bit_1399', 'Bit_1400', 'Bit_1401', 'Bit_1402', 'Bit_1403', 'Bit_1404', 'Bit_1405', 'Bit_1406', 'Bit_1407', 'Bit_1408', 'Bit_1409', 'Bit_1410', 'Bit_1411', 'Bit_1412', 'Bit_1413', 'Bit_1414', 'Bit_1415', 'Bit_1416', 'Bit_1417', 'Bit_1418', 'Bit_1419', 'Bit_1420', 'Bit_1421', 'Bit_1422', 'Bit_1423', 'Bit_1424', 'Bit_1425', 'Bit_1426', 'Bit_1427', 'Bit_1428', 'Bit_1429', 'Bit_1430', 'Bit_1431', 'Bit_1432', 'Bit_1433', 'Bit_1434', 'Bit_1435', 'Bit_1436', 'Bit_1437', 'Bit_1438', 'Bit_1439', 'Bit_1440', 'Bit_1441', 'Bit_1442', 'Bit_1443', 'Bit_1444', 'Bit_1445', 'Bit_1446', 'Bit_1447', 'Bit_1448', 'Bit_1449', 'Bit_1450', 'Bit_1451', 'Bit_1452', 'Bit_1453', 'Bit_1454', 'Bit_1455', 'Bit_1456', 'Bit_1457', 'Bit_1458', 'Bit_1459', 'Bit_1460', 'Bit_1461', 'Bit_1462', 'Bit_1463', 'Bit_1464', 'Bit_1465', 'Bit_1466', 'Bit_1467', 'Bit_1468', 'Bit_1469', 'Bit_1470', 'Bit_1471', 'Bit_1472', 'Bit_1473', 'Bit_1474', 'Bit_1475', 'Bit_1476', 'Bit_1477', 'Bit_1478', 'Bit_1479', 'Bit_1480', 'Bit_1481', 'Bit_1482', 'Bit_1483', 'Bit_1484', 'Bit_1485', 'Bit_1486', 'Bit_1487', 'Bit_1488', 'Bit_1489', 'Bit_1490', 'Bit_1491', 'Bit_1492', 'Bit_1493', 'Bit_1494', 'Bit_1495', 'Bit_1496', 'Bit_1497', 'Bit_1498', 'Bit_1499', 'Bit_1500', 'Bit_1501', 'Bit_1502', 'Bit_1503', 'Bit_1504', 'Bit_1505', 'Bit_1506', 'Bit_1507', 'Bit_1508', 'Bit_1509', 'Bit_1510', 'Bit_1511', 'Bit_1512', 'Bit_1513', 'Bit_1514', 'Bit_1515', 'Bit_1516', 'Bit_1517', 'Bit_1518', 'Bit_1519', 'Bit_1520', 'Bit_1521', 'Bit_1522', 'Bit_1523', 'Bit_1524', 'Bit_1525', 'Bit_1526', 'Bit_1527', 'Bit_1528', 'Bit_1529', 'Bit_1530', 'Bit_1531', 'Bit_1532', 'Bit_1533', 'Bit_1534', 'Bit_1535', 'Bit_1536', 'Bit_1537', 'Bit_1538', 'Bit_1539', 'Bit_1540', 'Bit_1541', 'Bit_1542', 'Bit_1543', 'Bit_1544', 'Bit_1545', 'Bit_1546', 'Bit_1547', 'Bit_1548', 'Bit_1549', 'Bit_1550', 'Bit_1551', 'Bit_1552', 'Bit_1553', 'Bit_1554', 'Bit_1555', 'Bit_1556', 'Bit_1557', 'Bit_1558', 'Bit_1559', 'Bit_1560', 'Bit_1561', 'Bit_1562', 'Bit_1563', 'Bit_1564', 'Bit_1565', 'Bit_1566', 'Bit_1567', 'Bit_1568', 'Bit_1569', 'Bit_1570', 'Bit_1571', 'Bit_1572', 'Bit_1573', 'Bit_1574', 'Bit_1575', 'Bit_1576', 'Bit_1577', 'Bit_1578', 'Bit_1579', 'Bit_1580', 'Bit_1581', 'Bit_1582', 'Bit_1583', 'Bit_1584', 'Bit_1585', 'Bit_1586', 'Bit_1587', 'Bit_1588', 'Bit_1589', 'Bit_1590', 'Bit_1591', 'Bit_1592', 'Bit_1593', 'Bit_1594', 'Bit_1595', 'Bit_1596', 'Bit_1597', 'Bit_1598', 'Bit_1599', 'Bit_1600', 'Bit_1601', 'Bit_1602', 'Bit_1603', 'Bit_1604', 'Bit_1605', 'Bit_1606', 'Bit_1607', 'Bit_1608', 'Bit_1609', 'Bit_1610', 'Bit_1611', 'Bit_1612', 'Bit_1613', 'Bit_1614', 'Bit_1615', 'Bit_1616', 'Bit_1617', 'Bit_1618', 'Bit_1619', 'Bit_1620', 'Bit_1621', 'Bit_1622', 'Bit_1623', 'Bit_1624', 'Bit_1625', 'Bit_1626', 'Bit_1627', 'Bit_1628', 'Bit_1629', 'Bit_1630', 'Bit_1631', 'Bit_1632', 'Bit_1633', 'Bit_1634', 'Bit_1635', 'Bit_1636', 'Bit_1637', 'Bit_1638', 'Bit_1639', 'Bit_1640', 'Bit_1641', 'Bit_1642', 'Bit_1643', 'Bit_1644', 'Bit_1645', 'Bit_1646', 'Bit_1647', 'Bit_1648', 'Bit_1649', 'Bit_1650', 'Bit_1651', 'Bit_1652', 'Bit_1653', 'Bit_1654', 'Bit_1655', 'Bit_1656', 'Bit_1657', 'Bit_1658', 'Bit_1659', 'Bit_1660', 'Bit_1661', 'Bit_1662', 'Bit_1663', 'Bit_1664', 'Bit_1665', 'Bit_1666', 'Bit_1667', 'Bit_1668', 'Bit_1669', 'Bit_1670', 'Bit_1671', 'Bit_1672', 'Bit_1673', 'Bit_1674', 'Bit_1675', 'Bit_1676', 'Bit_1677', 'Bit_1678', 'Bit_1679', 'Bit_1680', 'Bit_1681', 'Bit_1682', 'Bit_1683', 'Bit_1684', 'Bit_1685', 'Bit_1686', 'Bit_1687', 'Bit_1688', 'Bit_1689', 'Bit_1690', 'Bit_1691', 'Bit_1692', 'Bit_1693', 'Bit_1694', 'Bit_1695', 'Bit_1696', 'Bit_1697', 'Bit_1698', 'Bit_1699', 'Bit_1700', 'Bit_1701', 'Bit_1702', 'Bit_1703', 'Bit_1704', 'Bit_1705', 'Bit_1706', 'Bit_1707', 'Bit_1708', 'Bit_1709', 'Bit_1710', 'Bit_1711', 'Bit_1712', 'Bit_1713', 'Bit_1714', 'Bit_1715', 'Bit_1716', 'Bit_1717', 'Bit_1718', 'Bit_1719', 'Bit_1720', 'Bit_1721', 'Bit_1722', 'Bit_1723', 'Bit_1724', 'Bit_1725', 'Bit_1726', 'Bit_1727', 'Bit_1728', 'Bit_1729', 'Bit_1730', 'Bit_1731', 'Bit_1732', 'Bit_1733', 'Bit_1734', 'Bit_1735', 'Bit_1736', 'Bit_1737', 'Bit_1738', 'Bit_1739', 'Bit_1740', 'Bit_1741', 'Bit_1742', 'Bit_1743', 'Bit_1744', 'Bit_1745', 'Bit_1746', 'Bit_1747', 'Bit_1748', 'Bit_1749', 'Bit_1750', 'Bit_1751', 'Bit_1752', 'Bit_1753', 'Bit_1754', 'Bit_1755', 'Bit_1756', 'Bit_1757', 'Bit_1758', 'Bit_1759', 'Bit_1760', 'Bit_1761', 'Bit_1762', 'Bit_1763', 'Bit_1764', 'Bit_1765', 'Bit_1766', 'Bit_1767', 'Bit_1768', 'Bit_1769', 'Bit_1770', 'Bit_1771', 'Bit_1772', 'Bit_1773', 'Bit_1774', 'Bit_1775', 'Bit_1776', 'Bit_1777', 'Bit_1778', 'Bit_1779', 'Bit_1780', 'Bit_1781', 'Bit_1782', 'Bit_1783', 'Bit_1784', 'Bit_1785', 'Bit_1786', 'Bit_1787', 'Bit_1788', 'Bit_1789', 'Bit_1790', 'Bit_1791', 'Bit_1792', 'Bit_1793', 'Bit_1794', 'Bit_1795', 'Bit_1796', 'Bit_1797', 'Bit_1798', 'Bit_1799', 'Bit_1800', 'Bit_1801', 'Bit_1802', 'Bit_1803', 'Bit_1804', 'Bit_1805', 'Bit_1806', 'Bit_1807', 'Bit_1808', 'Bit_1809', 'Bit_1810', 'Bit_1811', 'Bit_1812', 'Bit_1813', 'Bit_1814', 'Bit_1815', 'Bit_1816', 'Bit_1817', 'Bit_1818', 'Bit_1819', 'Bit_1820', 'Bit_1821', 'Bit_1822', 'Bit_1823', 'Bit_1824', 'Bit_1825', 'Bit_1826', 'Bit_1827', 'Bit_1828', 'Bit_1829', 'Bit_1830', 'Bit_1831', 'Bit_1832', 'Bit_1833', 'Bit_1834', 'Bit_1835', 'Bit_1836', 'Bit_1837', 'Bit_1838', 'Bit_1839', 'Bit_1840', 'Bit_1841', 'Bit_1842', 'Bit_1843', 'Bit_1844', 'Bit_1845', 'Bit_1846', 'Bit_1847', 'Bit_1848', 'Bit_1849', 'Bit_1850', 'Bit_1851', 'Bit_1852', 'Bit_1853', 'Bit_1854', 'Bit_1855', 'Bit_1856', 'Bit_1857', 'Bit_1858', 'Bit_1859', 'Bit_1860', 'Bit_1861', 'Bit_1862', 'Bit_1863', 'Bit_1864', 'Bit_1865', 'Bit_1866', 'Bit_1867', 'Bit_1868', 'Bit_1869', 'Bit_1870', 'Bit_1871', 'Bit_1872', 'Bit_1873', 'Bit_1874', 'Bit_1875', 'Bit_1876', 'Bit_1877', 'Bit_1878', 'Bit_1879', 'Bit_1880', 'Bit_1881', 'Bit_1882', 'Bit_1883', 'Bit_1884', 'Bit_1885', 'Bit_1886', 'Bit_1887', 'Bit_1888', 'Bit_1889', 'Bit_1890', 'Bit_1891', 'Bit_1892', 'Bit_1893', 'Bit_1894', 'Bit_1895', 'Bit_1896', 'Bit_1897', 'Bit_1898', 'Bit_1899', 'Bit_1900', 'Bit_1901', 'Bit_1902', 'Bit_1903', 'Bit_1904', 'Bit_1905', 'Bit_1906', 'Bit_1907', 'Bit_1908', 'Bit_1909', 'Bit_1910', 'Bit_1911', 'Bit_1912', 'Bit_1913', 'Bit_1914', 'Bit_1915', 'Bit_1916', 'Bit_1917', 'Bit_1918', 'Bit_1919', 'Bit_1920', 'Bit_1921', 'Bit_1922', 'Bit_1923', 'Bit_1924', 'Bit_1925', 'Bit_1926', 'Bit_1927', 'Bit_1928', 'Bit_1929', 'Bit_1930', 'Bit_1931', 'Bit_1932', 'Bit_1933', 'Bit_1934', 'Bit_1935', 'Bit_1936', 'Bit_1937', 'Bit_1938', 'Bit_1939', 'Bit_1940', 'Bit_1941', 'Bit_1942', 'Bit_1943', 'Bit_1944', 'Bit_1945', 'Bit_1946', 'Bit_1947', 'Bit_1948', 'Bit_1949', 'Bit_1950', 'Bit_1951', 'Bit_1952', 'Bit_1953', 'Bit_1954', 'Bit_1955', 'Bit_1956', 'Bit_1957', 'Bit_1958', 'Bit_1959', 'Bit_1960', 'Bit_1961', 'Bit_1962', 'Bit_1963', 'Bit_1964', 'Bit_1965', 'Bit_1966', 'Bit_1967', 'Bit_1968', 'Bit_1969', 'Bit_1970', 'Bit_1971', 'Bit_1972', 'Bit_1973', 'Bit_1974', 'Bit_1975', 'Bit_1976', 'Bit_1977', 'Bit_1978', 'Bit_1979', 'Bit_1980', 'Bit_1981', 'Bit_1982', 'Bit_1983', 'Bit_1984', 'Bit_1985', 'Bit_1986', 'Bit_1987', 'Bit_1988', 'Bit_1989', 'Bit_1990', 'Bit_1991', 'Bit_1992', 'Bit_1993', 'Bit_1994', 'Bit_1995', 'Bit_1996', 'Bit_1997', 'Bit_1998', 'Bit_1999', 'Bit_2000', 'Bit_2001', 'Bit_2002', 'Bit_2003', 'Bit_2004', 'Bit_2005', 'Bit_2006', 'Bit_2007', 'Bit_2008', 'Bit_2009', 'Bit_2010', 'Bit_2011', 'Bit_2012', 'Bit_2013', 'Bit_2014', 'Bit_2015', 'Bit_2016', 'Bit_2017', 'Bit_2018', 'Bit_2019', 'Bit_2020', 'Bit_2021', 'Bit_2022', 'Bit_2023', 'Bit_2024', 'Bit_2025', 'Bit_2026', 'Bit_2027', 'Bit_2028', 'Bit_2029', 'Bit_2030', 'Bit_2031', 'Bit_2032', 'Bit_2033', 'Bit_2034', 'Bit_2035', 'Bit_2036', 'Bit_2037', 'Bit_2038', 'Bit_2039', 'Bit_2040', 'Bit_2041', 'Bit_2042', 'Bit_2043', 'Bit_2044', 'Bit_2045', 'Bit_2046', 'Bit_2047']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Assuming combined_df is your initial DataFrame\n",
        "\n",
        "# Remove columns with all NaN values\n",
        "numeric_features = combined_df.select_dtypes(include=[np.number])\n",
        "numeric_features = numeric_features.dropna(axis=1, how='all')\n",
        "\n",
        "# Impute missing values in numeric_features\n",
        "# Here, we use the median for imputation, but you can choose another strategy\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "numeric_features_imputed = imputer.fit_transform(numeric_features)\n",
        "numeric_features_imputed_df = pd.DataFrame(numeric_features_imputed, columns=numeric_features.columns)\n",
        "\n",
        "# Separate the target variable\n",
        "if 'docking score' in combined_df.columns:\n",
        "    targets = combined_df['docking score']\n",
        "else:\n",
        "    targets = None\n",
        "    print(\"Target column 'docking score' was not found or defined, please verify your dataset.\")\n",
        "\n",
        "# Normalize the numeric features\n",
        "scaler = MinMaxScaler()\n",
        "normalized_features = scaler.fit_transform(numeric_features_imputed_df)\n",
        "normalized_features_df = pd.DataFrame(normalized_features, columns=numeric_features_imputed_df.columns)\n",
        "\n",
        "# Normalize the 'docking score', if it exists\n",
        "if targets is not None:\n",
        "    # Impute missing values in targets if necessary\n",
        "    targets_imputed = imputer.fit_transform(targets.values.reshape(-1, 1)).flatten()\n",
        "    target_scaler = MinMaxScaler()\n",
        "    normalized_targets = target_scaler.fit_transform(targets_imputed.reshape(-1, 1)).flatten()\n",
        "# Display the first few rows of the normalized features\n",
        "print(\"Normalized Features:\")\n",
        "print(normalized_features_df.head())\n",
        "\n",
        "# If the target variable exists and was normalized, display it as well\n",
        "if 'docking score' in combined_df.columns:\n",
        "    # Create a DataFrame for the normalized targets for easy viewing\n",
        "    normalized_targets_df = pd.DataFrame(normalized_targets, columns=['Normalized Docking Score'])\n",
        "    print(\"\\nNormalized Target Variable ('docking score'):\")\n",
        "    print(normalized_targets_df.head())\n",
        "else:\n",
        "    print(\"Target column 'docking score' was not found or defined, please verify your dataset.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "6v6TShbP-p9_",
        "outputId": "4838eb27-42cb-4e65-93dd-73602fb1c856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Features:\n",
            "   Entry ID  Source File Index  mmshare version  flags  Ionization Penalty  \\\n",
            "0  0.000000           0.000000              0.0    0.0            0.001004   \n",
            "1  0.000998           0.000998              0.0    0.0            0.005659   \n",
            "2  0.001996           0.001996              0.0    0.0            0.000026   \n",
            "3  0.002994           0.002994              0.0    0.0            0.004937   \n",
            "4  0.003992           0.003992              0.0    0.0            0.000000   \n",
            "\n",
            "   Ionization Penalty Charging  Ionization Penalty Neutral  State Penalty  \\\n",
            "0                          0.0                    0.009379       0.010340   \n",
            "1                          0.0                    0.052855       0.058269   \n",
            "2                          0.0                    0.000244       0.000000   \n",
            "3                          0.0                    0.046114       0.032420   \n",
            "4                          0.0                    0.000000       0.000000   \n",
            "\n",
            "   Charging Adjusted Penalty  Tot Q  ...  Bit_2038  Bit_2039  Bit_2040  \\\n",
            "0                   0.001112    0.5  ...       0.0       0.0       0.0   \n",
            "1                   0.006320    0.5  ...       0.0       0.0       0.0   \n",
            "2                   0.000000    0.5  ...       0.0       0.0       0.0   \n",
            "3                   0.003511    0.5  ...       0.0       0.0       0.0   \n",
            "4                   0.000000    0.5  ...       0.0       0.0       0.0   \n",
            "\n",
            "   Bit_2041  Bit_2042  Bit_2043  Bit_2044  Bit_2045  Bit_2046  Bit_2047  \n",
            "0       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "1       0.0       0.0       0.0       1.0       0.0       0.0       0.0  \n",
            "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "3       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "4       0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
            "\n",
            "[5 rows x 2389 columns]\n",
            "\n",
            "Normalized Target Variable ('docking score'):\n",
            "   Normalized Docking Score\n",
            "0                  0.000000\n",
            "1                  0.058442\n",
            "2                  0.070929\n",
            "3                  0.094406\n",
            "4                  0.111389\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(normalized_features_df, test_size = 0.2, random_state=20)\n",
        "valid, test = train_test_split(test, test_size = 0.5, random_state=20)"
      ],
      "metadata": {
        "id": "5nh5COPjChDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "id": "GhvQAdsbCqO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0afce5fd-d080-4658-f7f3-4840af58665e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.7)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Determine the number of input features. This should match the number of columns in your training data.\n",
        "n_features = normalized_features_df.shape[1]\n",
        "\n",
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# Adding the input layer and the first hidden layer\n",
        "model.add(Dense(units=1024, activation='relu', input_shape=(n_features,)))\n",
        "\n",
        "# Adding the second hidden layer\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "\n",
        "# Adding the output layer - since it's a regression problem, we have one output and no activation function\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Split your normalized_features_df and normalized_targets into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(normalized_features_df, normalized_targets, test_size=0.2, random_state=20)\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=32)\n",
        "\n",
        "# Optionally, evaluate the model on a test set if you have withheld one\n",
        "# model.evaluate(test_features, test_targets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJQW9k8lDqDB",
        "outputId": "3c3b0b4b-db2d-46f8-b440-453a262c4b7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "25/25 [==============================] - 3s 76ms/step - loss: 0.6866 - val_loss: 0.0514\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 2s 86ms/step - loss: 0.0254 - val_loss: 0.0230\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 2s 71ms/step - loss: 0.0157 - val_loss: 0.0205\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 2s 73ms/step - loss: 0.0112 - val_loss: 0.0178\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 2s 83ms/step - loss: 0.0073 - val_loss: 0.0165\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 2s 84ms/step - loss: 0.0053 - val_loss: 0.0156\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 2s 74ms/step - loss: 0.0032 - val_loss: 0.0130\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 3s 102ms/step - loss: 0.0021 - val_loss: 0.0123\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 2s 90ms/step - loss: 0.0016 - val_loss: 0.0136\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 2s 75ms/step - loss: 0.0015 - val_loss: 0.0112\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 2s 95ms/step - loss: 0.0012 - val_loss: 0.0116\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 3s 104ms/step - loss: 9.6520e-04 - val_loss: 0.0102\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 2s 78ms/step - loss: 8.7889e-04 - val_loss: 0.0099\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 7.2830e-04 - val_loss: 0.0105\n",
            "Epoch 15/100\n",
            "25/25 [==============================] - 2s 80ms/step - loss: 6.1635e-04 - val_loss: 0.0105\n",
            "Epoch 16/100\n",
            "25/25 [==============================] - 2s 77ms/step - loss: 5.8840e-04 - val_loss: 0.0100\n",
            "Epoch 17/100\n",
            "25/25 [==============================] - 2s 93ms/step - loss: 5.0016e-04 - val_loss: 0.0096\n",
            "Epoch 18/100\n",
            "25/25 [==============================] - 1s 49ms/step - loss: 4.1133e-04 - val_loss: 0.0097\n",
            "Epoch 19/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 3.5102e-04 - val_loss: 0.0099\n",
            "Epoch 20/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.6676e-04 - val_loss: 0.0098\n",
            "Epoch 21/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 3.2514e-04 - val_loss: 0.0094\n",
            "Epoch 22/100\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 3.0462e-04 - val_loss: 0.0096\n",
            "Epoch 23/100\n",
            "25/25 [==============================] - 1s 58ms/step - loss: 4.0916e-04 - val_loss: 0.0095\n",
            "Epoch 24/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 4.1775e-04 - val_loss: 0.0095\n",
            "Epoch 25/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 3.7142e-04 - val_loss: 0.0089\n",
            "Epoch 26/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 4.1137e-04 - val_loss: 0.0092\n",
            "Epoch 27/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 3.4894e-04 - val_loss: 0.0094\n",
            "Epoch 28/100\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 3.1425e-04 - val_loss: 0.0093\n",
            "Epoch 29/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 3.6632e-04 - val_loss: 0.0095\n",
            "Epoch 30/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 3.1225e-04 - val_loss: 0.0087\n",
            "Epoch 31/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.0232e-04 - val_loss: 0.0087\n",
            "Epoch 32/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.0042e-04 - val_loss: 0.0092\n",
            "Epoch 33/100\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 2.7179e-04 - val_loss: 0.0087\n",
            "Epoch 34/100\n",
            "25/25 [==============================] - 2s 61ms/step - loss: 3.9065e-04 - val_loss: 0.0091\n",
            "Epoch 35/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 6.1503e-04 - val_loss: 0.0096\n",
            "Epoch 36/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 6.2958e-04 - val_loss: 0.0089\n",
            "Epoch 37/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 4.3310e-04 - val_loss: 0.0086\n",
            "Epoch 38/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.2521e-04 - val_loss: 0.0087\n",
            "Epoch 39/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.8153e-04 - val_loss: 0.0088\n",
            "Epoch 40/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.4348e-04 - val_loss: 0.0086\n",
            "Epoch 41/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.0812e-04 - val_loss: 0.0081\n",
            "Epoch 42/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 2.3884e-04 - val_loss: 0.0088\n",
            "Epoch 43/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.5505e-04 - val_loss: 0.0085\n",
            "Epoch 44/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.5349e-04 - val_loss: 0.0084\n",
            "Epoch 45/100\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 2.2787e-04 - val_loss: 0.0088\n",
            "Epoch 46/100\n",
            "25/25 [==============================] - 2s 63ms/step - loss: 2.6368e-04 - val_loss: 0.0086\n",
            "Epoch 47/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 2.9514e-04 - val_loss: 0.0079\n",
            "Epoch 48/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.6023e-04 - val_loss: 0.0084\n",
            "Epoch 49/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.2688e-04 - val_loss: 0.0082\n",
            "Epoch 50/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 2.1125e-04 - val_loss: 0.0082\n",
            "Epoch 51/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 2.3487e-04 - val_loss: 0.0088\n",
            "Epoch 52/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.9685e-04 - val_loss: 0.0085\n",
            "Epoch 53/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.4017e-04 - val_loss: 0.0084\n",
            "Epoch 54/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 4.2113e-04 - val_loss: 0.0081\n",
            "Epoch 55/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 5.2692e-04 - val_loss: 0.0087\n",
            "Epoch 56/100\n",
            "25/25 [==============================] - 2s 63ms/step - loss: 5.3169e-04 - val_loss: 0.0087\n",
            "Epoch 57/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 5.5899e-04 - val_loss: 0.0080\n",
            "Epoch 58/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 7.5181e-04 - val_loss: 0.0081\n",
            "Epoch 59/100\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 5.7511e-04 - val_loss: 0.0091\n",
            "Epoch 60/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 4.6877e-04 - val_loss: 0.0079\n",
            "Epoch 61/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 4.3295e-04 - val_loss: 0.0084\n",
            "Epoch 62/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 3.8367e-04 - val_loss: 0.0081\n",
            "Epoch 63/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 5.0213e-04 - val_loss: 0.0086\n",
            "Epoch 64/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 5.9455e-04 - val_loss: 0.0088\n",
            "Epoch 65/100\n",
            "25/25 [==============================] - 2s 60ms/step - loss: 6.2886e-04 - val_loss: 0.0085\n",
            "Epoch 66/100\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 5.6567e-04 - val_loss: 0.0080\n",
            "Epoch 67/100\n",
            "25/25 [==============================] - 2s 65ms/step - loss: 4.7354e-04 - val_loss: 0.0081\n",
            "Epoch 68/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 3.8280e-04 - val_loss: 0.0085\n",
            "Epoch 69/100\n",
            "25/25 [==============================] - 1s 48ms/step - loss: 3.4989e-04 - val_loss: 0.0076\n",
            "Epoch 70/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 3.0101e-04 - val_loss: 0.0082\n",
            "Epoch 71/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.1499e-04 - val_loss: 0.0083\n",
            "Epoch 72/100\n",
            "25/25 [==============================] - 1s 50ms/step - loss: 1.6325e-04 - val_loss: 0.0079\n",
            "Epoch 73/100\n",
            "25/25 [==============================] - 1s 46ms/step - loss: 1.2596e-04 - val_loss: 0.0076\n",
            "Epoch 74/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.1720e-04 - val_loss: 0.0080\n",
            "Epoch 75/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.1323e-04 - val_loss: 0.0079\n",
            "Epoch 76/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 1.0118e-04 - val_loss: 0.0081\n",
            "Epoch 77/100\n",
            "25/25 [==============================] - 2s 63ms/step - loss: 8.0907e-05 - val_loss: 0.0076\n",
            "Epoch 78/100\n",
            "25/25 [==============================] - 2s 64ms/step - loss: 1.1222e-04 - val_loss: 0.0073\n",
            "Epoch 79/100\n",
            "25/25 [==============================] - 1s 44ms/step - loss: 2.0190e-04 - val_loss: 0.0077\n",
            "Epoch 80/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.1160e-04 - val_loss: 0.0078\n",
            "Epoch 81/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 1.8349e-04 - val_loss: 0.0081\n",
            "Epoch 82/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.5888e-04 - val_loss: 0.0080\n",
            "Epoch 83/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 3.4194e-04 - val_loss: 0.0080\n",
            "Epoch 84/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.8147e-04 - val_loss: 0.0073\n",
            "Epoch 85/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.6745e-04 - val_loss: 0.0075\n",
            "Epoch 86/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 1.9036e-04 - val_loss: 0.0076\n",
            "Epoch 87/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 2.0100e-04 - val_loss: 0.0081\n",
            "Epoch 88/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 1.6384e-04 - val_loss: 0.0073\n",
            "Epoch 89/100\n",
            "25/25 [==============================] - 1s 60ms/step - loss: 1.7667e-04 - val_loss: 0.0073\n",
            "Epoch 90/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 1.9846e-04 - val_loss: 0.0074\n",
            "Epoch 91/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 2.9617e-04 - val_loss: 0.0074\n",
            "Epoch 92/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 3.8986e-04 - val_loss: 0.0078\n",
            "Epoch 93/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 4.4531e-04 - val_loss: 0.0082\n",
            "Epoch 94/100\n",
            "25/25 [==============================] - 1s 42ms/step - loss: 4.1181e-04 - val_loss: 0.0081\n",
            "Epoch 95/100\n",
            "25/25 [==============================] - 1s 41ms/step - loss: 5.6175e-04 - val_loss: 0.0081\n",
            "Epoch 96/100\n",
            "25/25 [==============================] - 1s 43ms/step - loss: 6.4430e-04 - val_loss: 0.0083\n",
            "Epoch 97/100\n",
            "25/25 [==============================] - 1s 47ms/step - loss: 6.3120e-04 - val_loss: 0.0089\n",
            "Epoch 98/100\n",
            "25/25 [==============================] - 1s 53ms/step - loss: 0.0017 - val_loss: 0.0085\n",
            "Epoch 99/100\n",
            "25/25 [==============================] - 1s 54ms/step - loss: 0.0029 - val_loss: 0.0097\n",
            "Epoch 100/100\n",
            "25/25 [==============================] - 2s 63ms/step - loss: 0.0017 - val_loss: 0.0087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x794af877e170>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "Model Initialization: We use a Sequential model, which is a linear stack of layers.\n",
        "Input Layer: The first Dense layer acts as your input layer, with the input_shape parameter set to match the number of features in your dataset.\n",
        "Hidden Layers: Two hidden layers are included, with 1024 and 512 neurons, respectively, using ReLU activation functions to introduce non-linearity.\n",
        "Output Layer: For a regression problem, the output layer has one neuron and does not use an activation function, as we're predicting a continuous value.\n",
        "Compilation: The model uses the Adam optimizer and mean squared error as the loss function, which are common choices for regression problems.\n",
        "Training: The model is trained using the training data, with validation data provided to monitor performance on unseen data. The epochs parameter determines how many times the model will iterate over the entire dataset, and batch_size controls the number of samples per gradient update.\n",
        "This setup is a starting point. Based on your model's performance, you may want to experiment with different architectures, activation functions, optimizers, and learning rates to improve results."
      ],
      "metadata": {
        "id": "KlmcVdPsEjwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "# Assuming normalized_features_df and normalized_targets are defined and preprocessed\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Assuming normalized_features_df and normalized_targets are defined\n",
        "\n",
        "\n",
        "# First, split into training+validation and test sets\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "   normalized_features_df, normalized_targets, test_size=0.2, random_state=20)\n",
        "\n",
        "\n",
        "# Now split the training+validation set into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "   X_train_val, y_train_val, test_size=0.25, random_state=20)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "\n",
        "# Now you have:\n",
        "# - Training set: X_train, y_train\n",
        "# - Validation set: X_val, y_val\n",
        "# - Test set: X_test, y_test\n",
        "\n",
        "\n",
        "# The proportions of the splits will be:\n",
        "# 60% training, 20% validation, 20% test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Your model definition and training code here\n",
        "\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "loss = model.evaluate(X_val, y_val)\n",
        "\n",
        "\n",
        "# Predicting the values for validation set\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "\n",
        "# Calculating Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "\n",
        "\n",
        "# Calculating R^2 Score\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "\n",
        "print(f'Mean Squared Error on Validation Set: {loss}')\n",
        "print(f'Mean Absolute Error on Validation Set: {mae}')\n",
        "print(f'R^2 Score on Validation Set: {r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DjKKDA2KBbj",
        "outputId": "893f660e-224d-41e1-b3a0-21d5346bc54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 10ms/step - loss: 0.0062\n",
            "7/7 [==============================] - 0s 15ms/step\n",
            "Mean Squared Error on Validation Set: 0.006216417532414198\n",
            "Mean Absolute Error on Validation Set: 0.05024004007016978\n",
            "R^2 Score on Validation Set: 0.782910132024304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define a simple schedule to decrease the learning rate gradually\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),\n",
        "    ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),\n",
        "    LearningRateScheduler(scheduler, verbose=1)\n",
        "]\n",
        "\n",
        "# Assuming you have the Sequential model defined as 'model' and compiled\n",
        "\n",
        "# Train the model with the enhancements\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=100, batch_size=32, verbose=1,\n",
        "                    callbacks=callbacks)\n",
        "\n",
        "# Plotting the training and validation loss, including learning rate over epochs\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='validation')\n",
        "plt.title('Model Loss Progression')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['lr'], label='Learning Rate')\n",
        "plt.title('Learning Rate Progression')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3szMcWnIDuN6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "64c2d5f4-d139-497f-f56d-fd2a51b4a174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0002465970173943788.\n",
            "Epoch 1/100\n",
            "24/25 [===========================>..] - ETA: 0s - loss: 2.9273e-05"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r25/25 [==============================] - 2s 88ms/step - loss: 2.9119e-05 - val_loss: 0.0062 - lr: 2.4660e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0002465970173943788.\n",
            "Epoch 2/100\n",
            "25/25 [==============================] - 2s 75ms/step - loss: 1.2970e-05 - val_loss: 0.0063 - lr: 2.4660e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0002465970173943788.\n",
            "Epoch 3/100\n",
            "25/25 [==============================] - 2s 79ms/step - loss: 8.1131e-06 - val_loss: 0.0062 - lr: 2.4660e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0002465970173943788.\n",
            "Epoch 4/100\n",
            "25/25 [==============================] - 3s 118ms/step - loss: 6.3546e-06 - val_loss: 0.0062 - lr: 2.4660e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0002465970173943788.\n",
            "Epoch 5/100\n",
            "25/25 [==============================] - 2s 62ms/step - loss: 6.2184e-06 - val_loss: 0.0062 - lr: 2.4660e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0002465970173943788.\n",
            "Epoch 6/100\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 5.0925e-06 - val_loss: 0.0063 - lr: 2.4660e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0002465970173943788.\n",
            "Epoch 7/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 4.4563e-06 - val_loss: 0.0063 - lr: 2.4660e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0002465970173943788.\n",
            "Epoch 8/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 3.6961e-06 - val_loss: 0.0062 - lr: 2.4660e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0002465970173943788.\n",
            "Epoch 9/100\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 3.7657e-06 - val_loss: 0.0063 - lr: 2.4660e-04\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0002465970173943788.\n",
            "Epoch 10/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 3.7772e-06 - val_loss: 0.0062 - lr: 2.4660e-04\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.00022313020599540323.\n",
            "Epoch 11/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 3.1103e-06 - val_loss: 0.0063 - lr: 2.2313e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0002018965606112033.\n",
            "Epoch 12/100\n",
            "25/25 [==============================] - 1s 40ms/step - loss: 2.7410e-06 - val_loss: 0.0062 - lr: 2.0190e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.00018268356507178396.\n",
            "Epoch 13/100\n",
            "25/25 [==============================] - 1s 45ms/step - loss: 2.7777e-06 - val_loss: 0.0062 - lr: 1.8268e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.00016529893036931753.\n",
            "Epoch 14/100\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.8287e-06Restoring model weights from the end of the best epoch: 4.\n",
            "25/25 [==============================] - 1s 57ms/step - loss: 2.8287e-06 - val_loss: 0.0062 - lr: 1.6530e-04\n",
            "Epoch 14: early stopping\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the best epoch number\n",
        "best_epoch = np.argmin(history.history['val_loss']) + 1\n",
        "print(f\"The best model was obtained after {best_epoch} epochs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TvX_efrNrYQ",
        "outputId": "fb4bb7ce-a716-4c19-ad94-6583f44ed133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best model was obtained after 4 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additional Notes:\n",
        "Early Stopping: patience=10 means training will stop if the validation loss does not improve for 10 consecutive epochs. restore_best_weights=True ensures the model reverts to its state from when it achieved the best validation loss.\n",
        "Model Checkpoints: This saves the best version of your model based on validation loss. Ensure the directory for filepath exists or is writable.\n",
        "Learning Rate Scheduler: The defined scheduler function decreases the learning rate after 10 epochs. Adjust this strategy based on your observations of the training process.\n",
        "Plot Adjustments: The second subplot visualizes the learning rate over epochs, helping you understand how the learning rate changes over time due to the scheduler.\n",
        "By integrating these strategies, you can more effectively manage the training process, potentially leading to better model performance and efficiency."
      ],
      "metadata": {
        "id": "jy3Nv2XaGaGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Assuming normalized_features_df and normalized_targets are defined and preprocessed\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming normalized_features_df and normalized_targets are defined\n",
        "\n",
        "# First, split into training+validation and test sets\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    normalized_features_df, normalized_targets, test_size=0.2, random_state=20)\n",
        "\n",
        "# Now split the training+validation set into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.25, random_state=20)  # 0.25 x 0.8 = 0.2\n",
        "\n",
        "# Now you have:\n",
        "# - Training set: X_train, y_train\n",
        "# - Validation set: X_val, y_val\n",
        "# - Test set: X_test, y_test\n",
        "\n",
        "# The proportions of the splits will be:\n",
        "# 60% training, 20% validation, 20% test\n",
        "\n",
        "\n",
        "# Your model definition and training code here\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "loss = model.evaluate(X_val, y_val)\n",
        "\n",
        "# Predicting the values for validation set\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "# Calculating Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_val, y_pred)\n",
        "\n",
        "# Calculating R^2 Score\n",
        "r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error on Validation Set: {loss}')\n",
        "print(f'Mean Absolute Error on Validation Set: {mae}')\n",
        "print(f'R^2 Score on Validation Set: {r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7wv5j8PIj19",
        "outputId": "7588e7a8-3d60-40ac-b2bb-6f91723a6a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 30ms/step - loss: 0.0011\n",
            "7/7 [==============================] - 1s 38ms/step\n",
            "Mean Squared Error on Validation Set: 0.0011004761327058077\n",
            "Mean Absolute Error on Validation Set: 0.02488717759413263\n",
            "R^2 Score on Validation Set: 0.9511603412112293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the original training and validation sets for the final training phase\n",
        "X_train_val = np.concatenate((X_train, X_val), axis=0)\n",
        "y_train_val = np.concatenate((y_train, y_val), axis=0)"
      ],
      "metadata": {
        "id": "GoH6sBKMLneL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model (this should be the architecture of your best model)\n",
        "model = Sequential()\n",
        "model.add(Dense(units=1024, activation='relu', input_shape=(n_features,)))\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Retrain the model on the combined training and validation set\n",
        "model.fit(X_train_val, y_train_val, epochs=best_epoch, batch_size=32)\n",
        "\n",
        "# Now, evaluate the model on the test set (assuming X_test, y_test are your test features and targets)\n",
        "loss_on_test = model.evaluate(X_test, y_test)\n",
        "\n",
        "# Predict the test set results\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) on test set\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "\n",
        "# Calculating Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "# Calculating R^2 Score\n",
        "r2 = r2_score(y_test, y_pred_test)\n",
        "\n",
        "print(f'Mean Squared Error on Test Set: {mse_test}')\n",
        "print(f'Mean Absolute Error on Test Set: {mae}')\n",
        "print(f'R^2 Score on Test Set: {r2}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB9TCjMoLq68",
        "outputId": "e0cebfbd-184f-46ee-a209-978d7f0dff9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "25/25 [==============================] - 3s 58ms/step - loss: 0.4091\n",
            "Epoch 2/4\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.0203\n",
            "Epoch 3/4\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.0133\n",
            "Epoch 4/4\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.0080\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.0171\n",
            "7/7 [==============================] - 0s 8ms/step\n",
            "Mean Squared Error on Test Set: 0.017089145768085134\n",
            "Mean Absolute Error on Test Set: 0.09740753419600522\n",
            "R^2 Score on Test Set: 0.4032124644643761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gZOHVRnaMDqy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}